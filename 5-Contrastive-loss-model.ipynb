{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a48bb1b-af0f-4a2d-b09c-19259b0b4240",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8abe952e-83fd-4b94-9967-531e4e4ce8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necesary packages\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbfb2ada-c6dc-4e68-b77f-bc460fe5e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Basic information\n",
    "    \"AUTHOR\": \"Kiernan\",\n",
    "    \n",
    "    # Data information\n",
    "    \"IMAGE_SIZE\": 28,\n",
    "    \n",
    "    # Training params\n",
    "    \"LR_STYLE\": \"REDUCE\", #['REDUCE', 'SCHEDULE']\n",
    "    \"LR\": 0.001, #0.000001,\n",
    "    \"BATCH_SIZE\": 50,\n",
    "    \"EPOCHS\": 30,\n",
    "    \n",
    "    # Loss parameters\n",
    "    \"MARGIN\": 0.5,\n",
    "    \n",
    "    # Model params\n",
    "    # \"RUN_FOR_BASE\": \"3cmjv1lo\",\n",
    "    # \"FREEZE\": \"ALL\", #['ALL', 'BN', 'None'] which layers to freeze in the body model\n",
    "    \n",
    "    # Model params\n",
    "    \"FIRST_FILTERS\": 16,\n",
    "    \"CONV_LAYERS\": 4,\n",
    "    \"N_FILTERS\": 8,\n",
    "    \"KERNEL_SIZE\": (3,3),\n",
    "    \"EMBEDDING_SIZE\": 16,\n",
    "    \"VECTOR_SIZE\": 16,\n",
    "    \"DROPOUT\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18bdfe0-d763-4245-89ec-dfdb17b08aeb",
   "metadata": {},
   "source": [
    "## **Initialize WANDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a678c3-3808-4405-9dbd-ea13473cf43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mall-off-nothing\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\kiern/.netrc\n",
      "C:\\Users\\kiern\\anaconda3\\envs\\deep-clustering-analysis\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kmcguigan/deep-clustering-evaluation/runs/2b1hbny5\" target=\"_blank\">hearty-tree-49</a></strong> to <a href=\"https://wandb.ai/kmcguigan/deep-clustering-evaluation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from secrets import WANDB\n",
    "wandb.login(key=WANDB)\n",
    "run = wandb.init(project=\"deep-clustering-evaluation\", entity=\"kmcguigan\", group=\"contrastive-model\", config=config, job_type=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc26f17e-74d0-4511-a353-41975f515048",
   "metadata": {},
   "source": [
    "## **Loading Data**\n",
    "\n",
    "### **Load the presplit data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5460d1a-8fac-4ccf-8398-ef442d30416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (50000, 28, 28, 1) Val data shape: (10000, 28, 28, 1) Test data shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "with open('data/train.npy', mode='rb') as infile:\n",
    "    X_train = np.load(infile, allow_pickle=True)\n",
    "    y_train = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('data/val.npy', mode='rb') as infile:\n",
    "    X_val = np.load(infile, allow_pickle=True)\n",
    "    y_val = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('data/test.npy', mode='rb') as infile:\n",
    "    X_test = np.load(infile, allow_pickle=True)\n",
    "    y_test = np.load(infile, allow_pickle=True)\n",
    "\n",
    "print(f\"Train data shape: {X_train.shape} Val data shape: {X_val.shape} Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674e5bf-ec58-4c35-a3b0-f62ac8e43cae",
   "metadata": {},
   "source": [
    "### **Create a data generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c8f3dc-a9f6-46a1-b951-93f4ab9b5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, y, classes):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # image meta\n",
    "        self.dims = (config[\"IMAGE_SIZE\"], config[\"IMAGE_SIZE\"])\n",
    "        self.channels = 1\n",
    "        \n",
    "        # save the meta on what we will be choosing\n",
    "        self.batch_size = config[\"BATCH_SIZE\"]\n",
    "        self.samples_per_class = self.batch_size // len(classes)\n",
    "        self.half_samples = self.samples_per_class // 2\n",
    "        assert(self.batch_size % self.samples_per_class == 0)\n",
    "        \n",
    "        # create the image loader\n",
    "        self.indexer = {}\n",
    "        # min_samples = None\n",
    "        for cls in classes:\n",
    "            self.indexer[cls] = np.where(y==cls)[0]\n",
    "            \n",
    "        # save the size of a single epoch of data\n",
    "        self.batches_per_epoch = (self.X.shape[0] // self.batch_size) + 1\n",
    "        \n",
    "        super(CustomDataset, self).__init__()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.batches_per_epoch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        gc.collect()\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X1 = np.empty((self.batch_size, *self.dims, self.channels))\n",
    "        X2 = np.empty((self.batch_size, *self.dims, self.channels))\n",
    "        y = np.ones((self.batch_size), dtype=int)\n",
    "        batch_idx = 0\n",
    "        for cls in self.indexer.keys():\n",
    "            non_class_options = [key for key in self.indexer.keys() if key != cls]\n",
    "            samples = np.random.choice(self.indexer[cls], size=(2, self.samples_per_class), replace=False)\n",
    "            for i in range(self.half_samples):\n",
    "                random_negative_class = np.random.choice(non_class_options, size=1)[0]\n",
    "                negative_pair_idx = np.random.choice(self.indexer[random_negative_class], size=1)[0]\n",
    "                samples[1, i] = negative_pair_idx\n",
    "                y[batch_idx+i] = 0\n",
    "            X1[batch_idx:batch_idx+self.samples_per_class, :, :, :] = self.X[samples[0,:], :, :, :]\n",
    "            X2[batch_idx:batch_idx+self.samples_per_class, :, :, :] = self.X[samples[1,:], :, :, :]\n",
    "            batch_idx = batch_idx+self.samples_per_class\n",
    "        return (X1,X2),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7648b6d7-3157-4d14-bda6-45e97ff05bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(X_train, y_train, [i for i in range(10)])\n",
    "val_ds = CustomDataset(X_val, y_val, [i for i in range(10)])\n",
    "test_ds = CustomDataset(X_test, y_test, [i for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d1dc5-7cc8-49ba-bd00-f9ea1a846d27",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Define Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285833cb-7c38-4283-86c4-db1614d307db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_distance(embeddings, squared=False):\n",
    "    dot = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "    square_norm = tf.linalg.diag_part(dot)\n",
    "    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot + tf.expand_dims(square_norm, 0)\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "    if(not squared):\n",
    "        mask = tf.cast(tf.equal(distances, 0.0), tf.float32)\n",
    "        distances = distances + mask * 1e-16\n",
    "        distances = tf.sqrt(distances)\n",
    "        distances = distances * (1.0 - mask)\n",
    "    return distances\n",
    "\n",
    "def angular_distances(embeddings):\n",
    "    embeddings = tf.math.l2_normalize(embeddings, axis=-1)\n",
    "    angular_distances = 1 - tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "    angular_distances = tf.maximum(angular_distances, 0.0)\n",
    "    mask_offdiag = tf.ones_like(angular_distances) - tf.linalg.diag(tf.ones([tf.shape(angular_distances)[0]]))\n",
    "    angular_distances = tf.math.multiply(angular_distances, mask_offdiag)\n",
    "    return angular_distances\n",
    "\n",
    "def apply_metric(embeddings, labels, metric):\n",
    "    adj = tf.equal(labels, tf.transpose(labels))\n",
    "    adj_not = tf.math.logical_not(adj)\n",
    "    adj = tf.cast(adj, tf.float32) - tf.linalg.diag(tf.ones([tf.shape(labels)[0]]))\n",
    "    adj_not = tf.cast(adj_not, tf.float32)\n",
    "    distances = metric(embeddings)\n",
    "    pos_dist = tf.math.multiply(distances, adj)\n",
    "    neg_dist = tf.math.multiply(distances, adj_not)\n",
    "    pos_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(pos_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    neg_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(neg_dist, mask=tf.math.equal(adj_not, 1.0)))\n",
    "    return pos_dist_mean, neg_dist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "977041ab-3c9a-43d2-b06e-e84e13cd90d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positive_distance(labels, embeddings):\n",
    "    adj = tf.equal(labels, tf.transpose(labels))\n",
    "    adj = tf.cast(adj, tf.float32) - tf.linalg.diag(tf.ones([tf.shape(labels)[0]]))\n",
    "    distances = pairwise_distance(embeddings)\n",
    "    pos_dist = tf.math.multiply(distances, adj)\n",
    "    pos_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(pos_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return pos_dist_mean\n",
    "\n",
    "def negative_distance(labels, embeddings):\n",
    "    adj = tf.math.logical_not(tf.equal(labels, tf.transpose(labels)))\n",
    "    adj = tf.cast(adj, tf.float32)\n",
    "    distances = pairwise_distance(embeddings)\n",
    "    neg_dist = tf.math.multiply(distances, adj)\n",
    "    neg_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(neg_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return neg_dist_mean\n",
    "\n",
    "def positive_angular(labels, embeddings):\n",
    "    adj = tf.equal(labels, tf.transpose(labels))\n",
    "    adj = tf.cast(adj, tf.float32) - tf.linalg.diag(tf.ones([tf.shape(labels)[0]]))\n",
    "    distances = angular_distances(embeddings)\n",
    "    pos_dist = tf.math.multiply(distances, adj)\n",
    "    pos_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(pos_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return pos_dist_mean\n",
    "\n",
    "def negative_angular(labels, embeddings):\n",
    "    adj = tf.math.logical_not(tf.equal(labels, tf.transpose(labels)))\n",
    "    adj = tf.cast(adj, tf.float32)\n",
    "    distances = angular_distances(embeddings)\n",
    "    neg_dist = tf.math.multiply(distances, adj)\n",
    "    neg_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(neg_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return neg_dist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e32cec-46b6-4ab3-a308-d06045d15e3d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetricHandler:\n",
    "    def __init__(self, metric):\n",
    "        self.has_read = {0: False, 1: False}\n",
    "        self.metric = metric\n",
    "        self.results = {0: None, 1: None}\n",
    "        \n",
    "    def read_metric(self, reader, embeddings, labels):\n",
    "        if(self.has_read[reader]):\n",
    "            raise Excpetion(f'{reader} reader re-reading data it already has')\n",
    "        other = 1 - reader\n",
    "        if(self.has_read[other]):\n",
    "            value = self.results[reader]\n",
    "            self.results[0] = None\n",
    "            self.results[1] = None\n",
    "            return value\n",
    "        metric_results = apply_metric(embeddings, labels, self.metric)\n",
    "        self.results[0] = metric_results[0]\n",
    "        self.results[1] = metric_results[1]\n",
    "        return self.results[reader]\n",
    "    \n",
    "distance_handler = MetricHandler(pairwise_distance)\n",
    "angular_handler = MetricHandler(angular_distances)\n",
    "    \n",
    "def pos_distance(labels, embeddings):\n",
    "    return distance_handler.read_metric(0, embeddings, labels)\n",
    "def neg_distance(labels, embeddings):\n",
    "    return distance_handler.read_metric(1, embeddings, labels)\n",
    "\n",
    "def pos_angle(labels, embeddings):\n",
    "    return angular_handler.read_metric(0, embeddings, labels)\n",
    "def neg_angle(labels, embeddings):\n",
    "    return angular_handler.read_metric(1, embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a4ea94-a7b5-4e4b-81e7-c573698d0e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(plot=False, batch_size=config['BATCH_SIZE'], epochs=config['EPOCHS']):\n",
    "    lr_start   = config['LR']\n",
    "    lr_max     = config['LR'] * 5 * batch_size  \n",
    "    lr_min     = config['LR']\n",
    "    lr_ramp_ep = 4\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.9\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "    if(plot):\n",
    "        epochs = list(range(epochs))\n",
    "        learning_rates = [lrfn(x) for x in epochs]\n",
    "        plt.scatter(epochs,learning_rates)\n",
    "        ax = plt.gca()\n",
    "        ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "        plt.show()\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback\n",
    "\n",
    "if(config[\"LR_STYLE\"] == \"SCHEDULE\"):\n",
    "    lr_callback = get_lr_callback(plot=True)\n",
    "elif(config[\"LR_STYLE\"] == \"REDUCE\"):\n",
    "    lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=2)\n",
    "else:\n",
    "    raise Exception(f\"config LR_STYLE {config['LR_STYLE']} is not understood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ec022-7515-4d49-a2d9-6ed7ed6d4a2d",
   "metadata": {},
   "source": [
    "## **Create Model**\n",
    "\n",
    "### **Load the pretrained body model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d9e9808-3113-44b4-83c0-80ad30916c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "def freeze_BN(model):\n",
    "    # Unfreeze layers while leaving BatchNorm layers frozen\n",
    "    for layer in model.layers:\n",
    "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "            \n",
    "def freeze_none(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb10cd0-d568-4c40-aa6b-d4e42c4bd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_file = wandb.restore('body.h5', run_path=f\"kmcguigan/deep-clustering-evaluation/{config['RUN_FOR_BASE']}\")\n",
    "# body = tf.keras.models.load_model(body_file.name)\n",
    "# body_output_shape = body.layers[-1].output_shape[-1]\n",
    "# config['EMBEDDING_SIZE'] = body_output_shape\n",
    "# if(config[\"FREEZE\"] == \"ALL\"):\n",
    "#     freeze_all(body)\n",
    "# elif(config[\"FREEZE\"] == \"BN\"):\n",
    "#     freeze_BN(body)\n",
    "# elif(config[\"FREEZE\"] == \"None\"):\n",
    "#     freeze_none(body)\n",
    "# else:\n",
    "#     raise Excpetion(f\"config FREEZE is set to {config['FREEZE']} but this freeze method is not understood\")\n",
    "# body.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439cbcd1-66eb-431d-9850-6b3e04840dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"body\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 14, 14, 16)       64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 16)        144       \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 16)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,408\n",
      "Trainable params: 3,312\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_body(image_shape):\n",
    "    inputs = tf.keras.layers.Input(shape=image_shape)\n",
    "    \n",
    "    def conv_block(layer_inputs, n_filters, kernel_size, **kwargs):\n",
    "        x = tf.keras.layers.Conv2D(n_filters, kernel_size, padding=\"same\", **kwargs)(layer_inputs)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        return x\n",
    "    \n",
    "    x = conv_block(inputs, config[\"FIRST_FILTERS\"], config[\"KERNEL_SIZE\"], strides=2)\n",
    "    for _ in range(config[\"CONV_LAYERS\"]):\n",
    "        x = conv_block(x, config[\"N_FILTERS\"], config[\"KERNEL_SIZE\"])\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(config[\"EMBEDDING_SIZE\"], (1,1), padding=\"same\")(x)\n",
    "    outputs = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    return tf.keras.models.Model(inputs=inputs, outputs=outputs, name=\"body\")\n",
    "\n",
    "body = create_body(X_train.shape[1:])\n",
    "body.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa563da5-ade8-494d-bd6e-6db8bcb53a4f",
   "metadata": {},
   "source": [
    "### **Create the head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80f7f57-2ebd-41e2-a81e-8f69847a6566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 16)]              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 16)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272\n",
      "Trainable params: 272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_head(input_shape):\n",
    "    inputs = tf.keras.layers.Input(shape=(input_shape,))\n",
    "    x = tf.keras.layers.Dropout(config[\"DROPOUT\"])(inputs)\n",
    "    x = tf.keras.layers.Dense(config['VECTOR_SIZE'])(x)\n",
    "    outputs = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1))(x)\n",
    "    return tf.keras.models.Model(inputs=inputs, outputs=outputs, name=\"head\")\n",
    "\n",
    "head = create_head(input_shape=config['EMBEDDING_SIZE'])\n",
    "head.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb33df-6a61-4229-b696-973498879b81",
   "metadata": {},
   "source": [
    "### **Create the full model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdeedd8d-209b-41a4-9630-57fa1c0783bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_model = tf.keras.models.Sequential([\n",
    "#     body,\n",
    "#     head\n",
    "# ],\n",
    "#     name=\"combinedModel\"\n",
    "# )\n",
    "\n",
    "class FullModel(tf.keras.layers.Layer):\n",
    "    def __init__(self, body, head):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.body = body\n",
    "        self.head = head\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(FullModel, self).get_config()\n",
    "        config.update({\n",
    "            \"body\": self.body,\n",
    "            \"head\": self.head\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        image1, image2 = inputs\n",
    "        x1 = self.head(self.body(image1))\n",
    "        x2 = self.head(self.body(image2))\n",
    "        sumSquared = K.sum(K.square(x1 - x2), axis=1, keepdims=True)\n",
    "        return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n",
    "\n",
    "def get_model(image_size):\n",
    "    input1 = tf.keras.layers.Input(shape=image_size)\n",
    "    input2 = tf.keras.layers.Input(shape=image_size)\n",
    "    outputs = FullModel(body, head)([input1, input2])\n",
    "    return tf.keras.models.Model(inputs=[input1, input2], outputs=outputs)\n",
    "\n",
    "model = get_model(train_ds[0][0][0].shape[1:])\n",
    "loss = tfa.losses.ContrastiveLoss(margin=config[\"MARGIN\"])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=config['LR'])\n",
    "metrics = [\n",
    "    positive_distance,\n",
    "    negative_distance,\n",
    "    positive_angular,\n",
    "    negative_angular\n",
    "]\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44681c0-fed9-40f6-ba5e-ccc868f11103",
   "metadata": {},
   "source": [
    "## **Evaluate Models Initial Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e74224f-c9b9-4ec1-b902-f008d240b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster_accuracy(X, y):\n",
    "    embeddings = head(body(X))\n",
    "    kmeans = KMeans(n_clusters=10, random_state=123)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    \n",
    "    label_mappings = {}\n",
    "    for label in np.unique(labels):\n",
    "        values, counts = np.unique(y[np.where(labels==label)], return_counts=True)\n",
    "        label_mappings[label] = values[np.argmax(counts)]\n",
    "    print(label_mappings)\n",
    "    \n",
    "    map_labels = np.vectorize(lambda x: label_mappings[x])\n",
    "    mapped_labels = map_labels(labels)\n",
    "    return accuracy_score(y.reshape((-1,1)), mapped_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3b3de4e-1efd-4efa-9aa7-3fbdc7d650ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 7, 1: 0, 2: 1, 3: 3, 4: 1, 5: 2, 6: 8, 7: 3, 8: 7, 9: 6}\n",
      "Initial test accuracy:  0.3002\n"
     ]
    }
   ],
   "source": [
    "initial_test_acc = kmeans_cluster_accuracy(X_test, y_test)\n",
    "print(\"Initial test accuracy: \", initial_test_acc)\n",
    "run.log({'test/init-test-clustering-accuracy': initial_test_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bddf076-3b72-4518-9d89-29072f54f187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 6, 2: 7, 3: 3, 4: 3, 5: 1, 6: 3, 7: 1, 8: 7, 9: 9}\n",
      "Initial validation accuracy:  0.2998\n"
     ]
    }
   ],
   "source": [
    "initial_val_acc = kmeans_cluster_accuracy(X_val, y_val)\n",
    "print(\"Initial validation accuracy: \", initial_val_acc)\n",
    "run.log({'test/init-val-clustering-accuracy': initial_val_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df6119-f868-4379-8f18-0125857dec73",
   "metadata": {},
   "source": [
    "## **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fe49ad3-8eab-4f11-9175-e4f6e44ced69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1001/1001 [==============================] - 34s 32ms/step - loss: 0.0452 - positive_distance: 0.1019 - negative_distance: 0.1764 - positive_angular: 5.4143e-08 - negative_angular: 5.4690e-08 - val_loss: 0.0247 - val_positive_distance: 0.0962 - val_negative_distance: 0.2580 - val_positive_angular: 5.3943e-08 - val_negative_angular: 5.4263e-08 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1001/1001 [==============================] - 33s 33ms/step - loss: 0.0266 - positive_distance: 0.0988 - negative_distance: 0.2537 - positive_angular: 5.4360e-08 - negative_angular: 5.5033e-08 - val_loss: 0.0204 - val_positive_distance: 0.0994 - val_negative_distance: 0.2986 - val_positive_angular: 5.4432e-08 - val_negative_angular: 5.4559e-08 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "1001/1001 [==============================] - 32s 32ms/step - loss: 0.0238 - positive_distance: 0.0986 - negative_distance: 0.2742 - positive_angular: 5.4776e-08 - negative_angular: 5.5237e-08 - val_loss: 0.0181 - val_positive_distance: 0.0945 - val_negative_distance: 0.3123 - val_positive_angular: 5.4276e-08 - val_negative_angular: 5.4444e-08 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1001/1001 [==============================] - 32s 32ms/step - loss: 0.0223 - positive_distance: 0.0988 - negative_distance: 0.2888 - positive_angular: 5.3567e-08 - negative_angular: 5.4048e-08 - val_loss: 0.0180 - val_positive_distance: 0.0891 - val_negative_distance: 0.3007 - val_positive_angular: 5.4164e-08 - val_negative_angular: 5.4693e-08 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "1001/1001 [==============================] - 31s 31ms/step - loss: 0.0214 - positive_distance: 0.0993 - negative_distance: 0.2984 - positive_angular: 5.3633e-08 - negative_angular: 5.3912e-08 - val_loss: 0.0168 - val_positive_distance: 0.0916 - val_negative_distance: 0.3224 - val_positive_angular: 5.4904e-08 - val_negative_angular: 5.5044e-08 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "1001/1001 [==============================] - 32s 32ms/step - loss: 0.0206 - positive_distance: 0.0989 - negative_distance: 0.3049 - positive_angular: 5.4771e-08 - negative_angular: 5.5241e-08 - val_loss: 0.0161 - val_positive_distance: 0.0871 - val_negative_distance: 0.3185 - val_positive_angular: 5.3724e-08 - val_negative_angular: 5.4566e-08 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1001/1001 [==============================] - 31s 31ms/step - loss: 0.0203 - positive_distance: 0.1001 - negative_distance: 0.3113 - positive_angular: 5.4616e-08 - negative_angular: 5.5244e-08 - val_loss: 0.0153 - val_positive_distance: 0.0904 - val_negative_distance: 0.3381 - val_positive_angular: 5.4390e-08 - val_negative_angular: 5.5297e-08 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "1001/1001 [==============================] - 35s 35ms/step - loss: 0.0195 - positive_distance: 0.0996 - negative_distance: 0.3186 - positive_angular: 5.3726e-08 - negative_angular: 5.4335e-08 - val_loss: 0.0153 - val_positive_distance: 0.0931 - val_negative_distance: 0.3475 - val_positive_angular: 5.4482e-08 - val_negative_angular: 5.4833e-08 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "1001/1001 [==============================] - 31s 31ms/step - loss: 0.0191 - positive_distance: 0.0994 - negative_distance: 0.3222 - positive_angular: 5.4234e-08 - negative_angular: 5.4837e-08 - val_loss: 0.0153 - val_positive_distance: 0.0915 - val_negative_distance: 0.3377 - val_positive_angular: 5.4460e-08 - val_negative_angular: 5.4798e-08 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "1001/1001 [==============================] - 31s 31ms/step - loss: 0.0189 - positive_distance: 0.1009 - negative_distance: 0.3267 - positive_angular: 5.4651e-08 - negative_angular: 5.5265e-08 - val_loss: 0.0150 - val_positive_distance: 0.0950 - val_negative_distance: 0.3500 - val_positive_angular: 5.6992e-08 - val_negative_angular: 5.7389e-08 - lr: 9.0000e-04\n",
      "Epoch 11/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0187 - positive_distance: 0.1002 - negative_distance: 0.3285 - positive_angular: 5.4350e-08 - negative_angular: 5.5049e-08 - val_loss: 0.0148 - val_positive_distance: 0.0977 - val_negative_distance: 0.3634 - val_positive_angular: 5.4293e-08 - val_negative_angular: 5.4913e-08 - lr: 9.0000e-04\n",
      "Epoch 12/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0183 - positive_distance: 0.1016 - negative_distance: 0.3354 - positive_angular: 5.3687e-08 - negative_angular: 5.4082e-08 - val_loss: 0.0145 - val_positive_distance: 0.0906 - val_negative_distance: 0.3464 - val_positive_angular: 5.5139e-08 - val_negative_angular: 5.5588e-08 - lr: 9.0000e-04\n",
      "Epoch 13/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0180 - positive_distance: 0.1014 - negative_distance: 0.3378 - positive_angular: 5.4417e-08 - negative_angular: 5.5175e-08 - val_loss: 0.0147 - val_positive_distance: 0.0929 - val_negative_distance: 0.3484 - val_positive_angular: 5.3866e-08 - val_negative_angular: 5.4622e-08 - lr: 9.0000e-04\n",
      "Epoch 14/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0181 - positive_distance: 0.1018 - negative_distance: 0.3387 - positive_angular: 5.5176e-08 - negative_angular: 5.5763e-08 - val_loss: 0.0135 - val_positive_distance: 0.0980 - val_negative_distance: 0.3845 - val_positive_angular: 5.4443e-08 - val_negative_angular: 5.4781e-08 - lr: 9.0000e-04\n",
      "Epoch 15/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0177 - positive_distance: 0.1022 - negative_distance: 0.3434 - positive_angular: 5.4173e-08 - negative_angular: 5.4627e-08 - val_loss: 0.0139 - val_positive_distance: 0.0947 - val_negative_distance: 0.3609 - val_positive_angular: 5.5171e-08 - val_negative_angular: 5.5120e-08 - lr: 9.0000e-04\n",
      "Epoch 16/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0176 - positive_distance: 0.1028 - negative_distance: 0.3454 - positive_angular: 5.3860e-08 - negative_angular: 5.4476e-08 - val_loss: 0.0144 - val_positive_distance: 0.0974 - val_negative_distance: 0.3633 - val_positive_angular: 5.2658e-08 - val_negative_angular: 5.3271e-08 - lr: 9.0000e-04\n",
      "Epoch 17/30\n",
      "1001/1001 [==============================] - 31s 31ms/step - loss: 0.0176 - positive_distance: 0.1034 - negative_distance: 0.3482 - positive_angular: 5.4678e-08 - negative_angular: 5.5203e-08 - val_loss: 0.0133 - val_positive_distance: 0.0974 - val_negative_distance: 0.3782 - val_positive_angular: 5.4503e-08 - val_negative_angular: 5.4921e-08 - lr: 8.1000e-04\n",
      "Epoch 18/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0171 - positive_distance: 0.1036 - negative_distance: 0.3541 - positive_angular: 5.4696e-08 - negative_angular: 5.4887e-08 - val_loss: 0.0135 - val_positive_distance: 0.1004 - val_negative_distance: 0.3891 - val_positive_angular: 5.4614e-08 - val_negative_angular: 5.4601e-08 - lr: 8.1000e-04\n",
      "Epoch 19/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0172 - positive_distance: 0.1046 - negative_distance: 0.3546 - positive_angular: 5.3976e-08 - negative_angular: 5.4193e-08 - val_loss: 0.0136 - val_positive_distance: 0.1021 - val_negative_distance: 0.3894 - val_positive_angular: 5.4366e-08 - val_negative_angular: 5.4695e-08 - lr: 8.1000e-04\n",
      "Epoch 20/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0169 - positive_distance: 0.1044 - negative_distance: 0.3591 - positive_angular: 5.4848e-08 - negative_angular: 5.5281e-08 - val_loss: 0.0134 - val_positive_distance: 0.0956 - val_negative_distance: 0.3760 - val_positive_angular: 5.4859e-08 - val_negative_angular: 5.5539e-08 - lr: 7.2900e-04\n",
      "Epoch 21/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0170 - positive_distance: 0.1045 - negative_distance: 0.3577 - positive_angular: 5.4715e-08 - negative_angular: 5.5351e-08 - val_loss: 0.0130 - val_positive_distance: 0.0997 - val_negative_distance: 0.3940 - val_positive_angular: 5.3070e-08 - val_negative_angular: 5.3606e-08 - lr: 7.2900e-04\n",
      "Epoch 22/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0167 - positive_distance: 0.1049 - negative_distance: 0.3627 - positive_angular: 5.4490e-08 - negative_angular: 5.4993e-08 - val_loss: 0.0137 - val_positive_distance: 0.0993 - val_negative_distance: 0.3824 - val_positive_angular: 5.3687e-08 - val_negative_angular: 5.4613e-08 - lr: 7.2900e-04\n",
      "Epoch 23/30\n",
      "1001/1001 [==============================] - 31s 31ms/step - loss: 0.0167 - positive_distance: 0.1056 - negative_distance: 0.3642 - positive_angular: 5.3839e-08 - negative_angular: 5.4208e-08 - val_loss: 0.0136 - val_positive_distance: 0.0954 - val_negative_distance: 0.3750 - val_positive_angular: 5.4755e-08 - val_negative_angular: 5.5254e-08 - lr: 7.2900e-04\n",
      "Epoch 24/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0167 - positive_distance: 0.1057 - negative_distance: 0.3634 - positive_angular: 5.3982e-08 - negative_angular: 5.4526e-08 - val_loss: 0.0128 - val_positive_distance: 0.0974 - val_negative_distance: 0.3925 - val_positive_angular: 5.3687e-08 - val_negative_angular: 5.4202e-08 - lr: 6.5610e-04\n",
      "Epoch 25/30\n",
      "1001/1001 [==============================] - 31s 30ms/step - loss: 0.0166 - positive_distance: 0.1048 - negative_distance: 0.3643 - positive_angular: 5.4235e-08 - negative_angular: 5.4658e-08 - val_loss: 0.0127 - val_positive_distance: 0.1003 - val_negative_distance: 0.3995 - val_positive_angular: 5.4061e-08 - val_negative_angular: 5.4517e-08 - lr: 6.5610e-04\n",
      "Epoch 26/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0163 - positive_distance: 0.1050 - negative_distance: 0.3677 - positive_angular: 5.4583e-08 - negative_angular: 5.4871e-08 - val_loss: 0.0134 - val_positive_distance: 0.1028 - val_negative_distance: 0.3942 - val_positive_angular: 5.3757e-08 - val_negative_angular: 5.4541e-08 - lr: 6.5610e-04\n",
      "Epoch 27/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0164 - positive_distance: 0.1063 - negative_distance: 0.3696 - positive_angular: 5.4092e-08 - negative_angular: 5.4457e-08 - val_loss: 0.0126 - val_positive_distance: 0.0981 - val_negative_distance: 0.3926 - val_positive_angular: 5.4025e-08 - val_negative_angular: 5.4672e-08 - lr: 6.5610e-04\n",
      "Epoch 28/30\n",
      "1001/1001 [==============================] - 30s 30ms/step - loss: 0.0161 - positive_distance: 0.1053 - negative_distance: 0.3707 - positive_angular: 5.4005e-08 - negative_angular: 5.4435e-08 - val_loss: 0.0127 - val_positive_distance: 0.1002 - val_negative_distance: 0.4036 - val_positive_angular: 5.4195e-08 - val_negative_angular: 5.4928e-08 - lr: 5.9049e-04\n",
      "Epoch 29/30\n",
      "1001/1001 [==============================] - 31s 30ms/step - loss: 0.0162 - positive_distance: 0.1062 - negative_distance: 0.3715 - positive_angular: 5.4074e-08 - negative_angular: 5.4662e-08 - val_loss: 0.0128 - val_positive_distance: 0.0959 - val_negative_distance: 0.3850 - val_positive_angular: 5.3804e-08 - val_negative_angular: 5.4086e-08 - lr: 5.9049e-04\n",
      "Epoch 30/30\n",
      "1001/1001 [==============================] - 31s 31ms/step - loss: 0.0158 - positive_distance: 0.1051 - negative_distance: 0.3756 - positive_angular: 5.4539e-08 - negative_angular: 5.5247e-08 - val_loss: 0.0124 - val_positive_distance: 0.0976 - val_negative_distance: 0.3986 - val_positive_angular: 5.4169e-08 - val_negative_angular: 5.4442e-08 - lr: 5.3144e-04\n"
     ]
    }
   ],
   "source": [
    "stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "hist = model.fit(train_ds,\n",
    "                 validation_data=val_ds,\n",
    "                 epochs=config[\"EPOCHS\"],\n",
    "                 callbacks=[stopper, lr_callback, WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bee807c-9242-4fb6-958f-d80f834b9728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 2s 8ms/step - loss: 0.0124 - positive_distance: 0.0966 - negative_distance: 0.3969 - positive_angular: 5.4595e-08 - negative_angular: 5.5131e-08\n"
     ]
    }
   ],
   "source": [
    "ev = model.evaluate(test_ds, return_dict=True)\n",
    "log_dict = {f'test/{met}': val for met, val in ev.items()}\n",
    "run.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ea7a13-3ab5-4ed2-a8ea-a2fa648fc2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 8, 2: 5, 3: 9, 4: 7, 5: 0, 6: 3, 7: 4, 8: 6, 9: 2}\n",
      "Test accuracy:  0.9624\n"
     ]
    }
   ],
   "source": [
    "test_acc = kmeans_cluster_accuracy(X_test, y_test)\n",
    "print(\"Test accuracy: \", test_acc)\n",
    "run.log({'test/test-clustering-accuracy': test_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3c20eb8-dea8-4f6f-9887-0d93155adba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2, 1: 6, 2: 9, 3: 7, 4: 1, 5: 8, 6: 0, 7: 5, 8: 3, 9: 4}\n",
      "Validation accuracy:  0.958\n"
     ]
    }
   ],
   "source": [
    "val_acc = kmeans_cluster_accuracy(X_val, y_val)\n",
    "print(\"Validation accuracy: \", val_acc)\n",
    "run.log({'test/val-clustering-accuracy': val_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5b86879-55b6-459c-873d-bf31604aac9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16280... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>█████████▇▇▇▇▇▇▇▅▅▅▄▄▄▄▃▃▃▃▂▂▁</td></tr><tr><td>negative_angular</td><td>▄▅▆▂▁▆▆▃▄▆▅▂▆█▄▃▆▅▂▆▆▅▂▃▄▅▃▃▄▆</td></tr><tr><td>negative_distance</td><td>▁▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>positive_angular</td><td>▄▄▆▁▁▆▆▂▄▆▄▂▅█▄▂▆▆▃▇▆▅▂▃▄▅▃▃▃▅</td></tr><tr><td>positive_distance</td><td>▄▁▁▁▂▁▂▂▂▃▂▄▄▄▄▅▅▆▆▆▆▇▇▇▇▇█▇█▇</td></tr><tr><td>test/init-test-clustering-accuracy</td><td>▁</td></tr><tr><td>test/init-val-clustering-accuracy</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/negative_angular</td><td>▁</td></tr><tr><td>test/negative_distance</td><td>▁</td></tr><tr><td>test/positive_angular</td><td>▁</td></tr><tr><td>test/positive_distance</td><td>▁</td></tr><tr><td>test/test-clustering-accuracy</td><td>▁</td></tr><tr><td>test/val-clustering-accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>█▆▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▁▁▁</td></tr><tr><td>val_negative_angular</td><td>▃▃▃▃▄▃▄▄▄█▄▅▃▄▄▁▄▃▃▅▂▃▄▃▃▃▃▄▂▃</td></tr><tr><td>val_negative_distance</td><td>▁▃▄▃▄▄▅▅▅▅▆▅▅▇▆▆▇▇▇▇█▇▇▇██▇█▇█</td></tr><tr><td>val_positive_angular</td><td>▃▄▄▃▅▃▄▄▄█▄▅▃▄▅▁▄▄▄▅▂▃▄▃▃▃▃▃▃▃</td></tr><tr><td>val_positive_distance</td><td>▅▆▄▂▃▁▂▄▃▅▆▃▄▆▄▆▆▇█▅▇▆▅▆▇█▆▇▅▆</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>29</td></tr><tr><td>best_val_loss</td><td>0.01237</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.01579</td></tr><tr><td>lr</td><td>0.00053</td></tr><tr><td>negative_angular</td><td>0.0</td></tr><tr><td>negative_distance</td><td>0.37559</td></tr><tr><td>positive_angular</td><td>0.0</td></tr><tr><td>positive_distance</td><td>0.1051</td></tr><tr><td>test/init-test-clustering-accuracy</td><td>0.3002</td></tr><tr><td>test/init-val-clustering-accuracy</td><td>0.2998</td></tr><tr><td>test/loss</td><td>0.01237</td></tr><tr><td>test/negative_angular</td><td>0.0</td></tr><tr><td>test/negative_distance</td><td>0.3969</td></tr><tr><td>test/positive_angular</td><td>0.0</td></tr><tr><td>test/positive_distance</td><td>0.09661</td></tr><tr><td>test/test-clustering-accuracy</td><td>0.9624</td></tr><tr><td>test/val-clustering-accuracy</td><td>0.958</td></tr><tr><td>val_loss</td><td>0.01237</td></tr><tr><td>val_negative_angular</td><td>0.0</td></tr><tr><td>val_negative_distance</td><td>0.39861</td></tr><tr><td>val_positive_angular</td><td>0.0</td></tr><tr><td>val_positive_distance</td><td>0.0976</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">hearty-tree-49</strong>: <a href=\"https://wandb.ai/kmcguigan/deep-clustering-evaluation/runs/2b1hbny5\" target=\"_blank\">https://wandb.ai/kmcguigan/deep-clustering-evaluation/runs/2b1hbny5</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220307_210237-2b1hbny5\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
