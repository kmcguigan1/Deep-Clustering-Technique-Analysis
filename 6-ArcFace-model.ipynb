{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e328f5eb-d9d8-4b34-a4f4-c125665a5439",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3d15c6-0708-4a0b-a698-2a37f1e47009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necesary packages\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be88ad98-efd1-4a64-afb4-b356675f9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Basic information\n",
    "    \"AUTHOR\": \"Kiernan\",\n",
    "    \n",
    "    # Data information\n",
    "    \"IMAGE_SIZE\": (28,28,1),\n",
    "    \n",
    "    # Training params\n",
    "    \"LR_STYLE\": \"REDUCE\", #['REDUCE', 'SCHEDULE']\n",
    "    \"LR\": 0.001, #0.000001,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"EPOCHS\": 30,\n",
    "    \n",
    "    # Loss parameters\n",
    "    \"MARGIN\": 0.5,\n",
    "    \n",
    "    \n",
    "    # Model params\n",
    "    # \"RUN_FOR_BASE\": \"3cmjv1lo\",\n",
    "    # \"FREEZE\": \"ALL\", #['ALL', 'BN', 'None'] which layers to freeze in the body model\n",
    "    \n",
    "    # Model params\n",
    "    \"FIRST_FILTERS\": 16,\n",
    "    \"CONV_LAYERS\": 4,\n",
    "    \"N_FILTERS\": 8,\n",
    "    \"KERNEL_SIZE\": (3,3),\n",
    "    \"EMBEDDING_SIZE\": 16,\n",
    "    \"VECTOR_SIZE\": 16,\n",
    "    \"DROPOUT\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e537ce47-09e6-48d8-b508-0857f8e70f1e",
   "metadata": {},
   "source": [
    "## **Initialize WANDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ef434e-2881-4669-a98b-a2d849d9e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mall-off-nothing\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\kiern/.netrc\n",
      "C:\\Users\\kiern\\anaconda3\\envs\\deep-clustering-analysis\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kmcguigan/deep-clustering-evaluation/runs/279eu9pa\" target=\"_blank\">misty-smoke-54</a></strong> to <a href=\"https://wandb.ai/kmcguigan/deep-clustering-evaluation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from secrets import WANDB\n",
    "wandb.login(key=WANDB)\n",
    "run = wandb.init(project=\"deep-clustering-evaluation\", entity=\"kmcguigan\", group=\"arcface-model\", config=config, job_type=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ed87f-e2fa-453c-bea6-952f21333aec",
   "metadata": {},
   "source": [
    "## **Loading Data**\n",
    "\n",
    "### **Load the presplit data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5eaf12b-fc0a-42ee-831e-ac5d85dde1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (50000, 28, 28, 1) Val data shape: (10000, 28, 28, 1) Test data shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "with open('data/train.npy', mode='rb') as infile:\n",
    "    X_train = np.load(infile, allow_pickle=True)\n",
    "    y_train = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('data/val.npy', mode='rb') as infile:\n",
    "    X_val = np.load(infile, allow_pickle=True)\n",
    "    y_val = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('data/test.npy', mode='rb') as infile:\n",
    "    X_test = np.load(infile, allow_pickle=True)\n",
    "    y_test = np.load(infile, allow_pickle=True)\n",
    "\n",
    "print(f\"Train data shape: {X_train.shape} Val data shape: {X_val.shape} Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb1e57-8ae3-4e9f-b000-ceb11cd5a201",
   "metadata": {},
   "source": [
    "### **Create a data generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53203392-5fc1-41f8-a34b-815cff768bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(X, y):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(({\"images\":X,\"labels\":y},y))\n",
    "    ds = ds.cache().shuffle(X.shape[0]+1).batch(config[\"BATCH_SIZE\"]).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = to_dataset(X_train, y_train)\n",
    "val_ds = to_dataset(X_val, y_val)\n",
    "test_ds = to_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27274fe5-369a-4dfe-a06f-4d5dfd19b59f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Define Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c4f932-8181-454a-a4e5-aac29a33c932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_distance(embeddings, squared=False):\n",
    "    dot = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "    square_norm = tf.linalg.diag_part(dot)\n",
    "    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot + tf.expand_dims(square_norm, 0)\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "    if(not squared):\n",
    "        mask = tf.cast(tf.equal(distances, 0.0), tf.float32)\n",
    "        distances = distances + mask * 1e-16\n",
    "        distances = tf.sqrt(distances)\n",
    "        distances = distances * (1.0 - mask)\n",
    "    return distances\n",
    "\n",
    "def angular_distances(embeddings):\n",
    "    embeddings = tf.math.l2_normalize(embeddings, axis=-1)\n",
    "    angular_distances = 1 - tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "    angular_distances = tf.maximum(angular_distances, 0.0)\n",
    "    mask_offdiag = tf.ones_like(angular_distances) - tf.linalg.diag(tf.ones([tf.shape(angular_distances)[0]]))\n",
    "    angular_distances = tf.math.multiply(angular_distances, mask_offdiag)\n",
    "    return angular_distances\n",
    "\n",
    "def apply_metric(embeddings, labels, metric):\n",
    "    adj = tf.equal(labels, tf.transpose(labels))\n",
    "    adj_not = tf.math.logical_not(adj)\n",
    "    adj = tf.cast(adj, tf.float32) - tf.linalg.diag(tf.ones([tf.shape(labels)[0]]))\n",
    "    adj_not = tf.cast(adj_not, tf.float32)\n",
    "    distances = metric(embeddings)\n",
    "    pos_dist = tf.math.multiply(distances, adj)\n",
    "    neg_dist = tf.math.multiply(distances, adj_not)\n",
    "    pos_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(pos_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    neg_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(neg_dist, mask=tf.math.equal(adj_not, 1.0)))\n",
    "    return pos_dist_mean, neg_dist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327feae2-b259-4285-8d9f-37bd93a3b311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positive_distance(labels, embeddings):\n",
    "    adj = tf.equal(labels, tf.transpose(labels))\n",
    "    adj = tf.cast(adj, tf.float32) - tf.linalg.diag(tf.ones([tf.shape(labels)[0]]))\n",
    "    distances = pairwise_distance(embeddings)\n",
    "    pos_dist = tf.math.multiply(distances, adj)\n",
    "    pos_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(pos_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return pos_dist_mean\n",
    "\n",
    "def negative_distance(labels, embeddings):\n",
    "    adj = tf.math.logical_not(tf.equal(labels, tf.transpose(labels)))\n",
    "    adj = tf.cast(adj, tf.float32)\n",
    "    distances = pairwise_distance(embeddings)\n",
    "    neg_dist = tf.math.multiply(distances, adj)\n",
    "    neg_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(neg_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return neg_dist_mean\n",
    "\n",
    "def positive_angular(labels, embeddings):\n",
    "    adj = tf.equal(labels, tf.transpose(labels))\n",
    "    adj = tf.cast(adj, tf.float32) - tf.linalg.diag(tf.ones([tf.shape(labels)[0]]))\n",
    "    distances = angular_distances(embeddings)\n",
    "    pos_dist = tf.math.multiply(distances, adj)\n",
    "    pos_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(pos_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return pos_dist_mean\n",
    "\n",
    "def negative_angular(labels, embeddings):\n",
    "    adj = tf.math.logical_not(tf.equal(labels, tf.transpose(labels)))\n",
    "    adj = tf.cast(adj, tf.float32)\n",
    "    distances = angular_distances(embeddings)\n",
    "    neg_dist = tf.math.multiply(distances, adj)\n",
    "    neg_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(neg_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return neg_dist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc40eb0e-cfa7-4a8a-a757-c7b658b7d125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetricHandler:\n",
    "    def __init__(self, metric):\n",
    "        self.has_read = {0: False, 1: False}\n",
    "        self.metric = metric\n",
    "        self.results = {0: None, 1: None}\n",
    "        \n",
    "    def read_metric(self, reader, embeddings, labels):\n",
    "        if(self.has_read[reader]):\n",
    "            raise Excpetion(f'{reader} reader re-reading data it already has')\n",
    "        other = 1 - reader\n",
    "        if(self.has_read[other]):\n",
    "            value = self.results[reader]\n",
    "            self.results[0] = None\n",
    "            self.results[1] = None\n",
    "            return value\n",
    "        metric_results = apply_metric(embeddings, labels, self.metric)\n",
    "        self.results[0] = metric_results[0]\n",
    "        self.results[1] = metric_results[1]\n",
    "        return self.results[reader]\n",
    "    \n",
    "distance_handler = MetricHandler(pairwise_distance)\n",
    "angular_handler = MetricHandler(angular_distances)\n",
    "    \n",
    "def pos_distance(labels, embeddings):\n",
    "    return distance_handler.read_metric(0, embeddings, labels)\n",
    "def neg_distance(labels, embeddings):\n",
    "    return distance_handler.read_metric(1, embeddings, labels)\n",
    "\n",
    "def pos_angle(labels, embeddings):\n",
    "    return angular_handler.read_metric(0, embeddings, labels)\n",
    "def neg_angle(labels, embeddings):\n",
    "    return angular_handler.read_metric(1, embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6963757-8a58-42ce-ae38-1d3d32232830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(plot=False, batch_size=config['BATCH_SIZE'], epochs=config['EPOCHS']):\n",
    "    lr_start   = config['LR']\n",
    "    lr_max     = config['LR'] * 5 * batch_size  \n",
    "    lr_min     = config['LR']\n",
    "    lr_ramp_ep = 4\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.9\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "    if(plot):\n",
    "        epochs = list(range(epochs))\n",
    "        learning_rates = [lrfn(x) for x in epochs]\n",
    "        plt.scatter(epochs,learning_rates)\n",
    "        ax = plt.gca()\n",
    "        ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "        plt.show()\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback\n",
    "\n",
    "if(config[\"LR_STYLE\"] == \"SCHEDULE\"):\n",
    "    lr_callback = get_lr_callback(plot=True)\n",
    "elif(config[\"LR_STYLE\"] == \"REDUCE\"):\n",
    "    lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=2)\n",
    "else:\n",
    "    raise Exception(f\"config LR_STYLE {config['LR_STYLE']} is not understood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc8af1-6703-4636-bcb6-bdeb2ed58e4d",
   "metadata": {},
   "source": [
    "## **Create Model**\n",
    "\n",
    "### **Load the pretrained body model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8612f35-945d-42d9-a587-2cedbb64a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "def freeze_BN(model):\n",
    "    # Unfreeze layers while leaving BatchNorm layers frozen\n",
    "    for layer in model.layers:\n",
    "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "            \n",
    "def freeze_none(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc18a926-7262-4eb0-8896-b3cf7fdf5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"body\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 14, 14, 16)       64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 16)        144       \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 16)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,408\n",
      "Trainable params: 3,312\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_body(image_shape):\n",
    "    inputs = tf.keras.layers.Input(shape=image_shape)\n",
    "    \n",
    "    def conv_block(layer_inputs, n_filters, kernel_size, **kwargs):\n",
    "        x = tf.keras.layers.Conv2D(n_filters, kernel_size, padding=\"same\", **kwargs)(layer_inputs)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        return x\n",
    "    \n",
    "    x = conv_block(inputs, config[\"FIRST_FILTERS\"], config[\"KERNEL_SIZE\"], strides=2)\n",
    "    for _ in range(config[\"CONV_LAYERS\"]):\n",
    "        x = conv_block(x, config[\"N_FILTERS\"], config[\"KERNEL_SIZE\"])\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(config[\"EMBEDDING_SIZE\"], (1,1), padding=\"same\")(x)\n",
    "    outputs = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    return tf.keras.models.Model(inputs=inputs, outputs=outputs, name=\"body\")\n",
    "\n",
    "body = create_body(X_train.shape[1:])\n",
    "body.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0346c-5250-4554-a204-86b7f9d8aa95",
   "metadata": {},
   "source": [
    "### **Create the head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3540639c-6bd9-4fca-af1e-db7983acdb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 16)]              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 16)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272\n",
      "Trainable params: 272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_head(input_shape):\n",
    "    inputs = tf.keras.layers.Input(shape=(input_shape,))\n",
    "    x = tf.keras.layers.Dropout(config[\"DROPOUT\"])(inputs)\n",
    "    x = tf.keras.layers.Dense(config['VECTOR_SIZE'])(x)\n",
    "    outputs = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1))(x)\n",
    "    return tf.keras.models.Model(inputs=inputs, outputs=outputs, name=\"head\")\n",
    "\n",
    "head = create_head(input_shape=config['EMBEDDING_SIZE'])\n",
    "head.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67956e-783d-4796-a5f7-3170418a83b7",
   "metadata": {},
   "source": [
    "### **Create the loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f44477-5a3e-4a1a-a5ed-06eedc2a953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arcmarginproduct class keras layer\n",
    "import math\n",
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dbc381-be0e-4de1-90fc-22910301960a",
   "metadata": {},
   "source": [
    "### **Create the full model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe1b374-3ff4-483b-9e14-5396b2734c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " images (InputLayer)            [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " body (Functional)              (None, 16)           3408        ['images[0][0]']                 \n",
      "                                                                                                  \n",
      " head (Functional)              (None, 16)           272         ['body[0][0]']                   \n",
      "                                                                                                  \n",
      " labels (InputLayer)            [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " arc_margin_product (ArcMarginP  (None, 10)          160         ['head[0][0]',                   \n",
      " roduct)                                                          'labels[0][0]']                 \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 10)           0           ['arc_margin_product[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,840\n",
      "Trainable params: 3,744\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(image_size, nclasses):\n",
    "    inputs = tf.keras.layers.Input(shape=image_size, name=\"images\")\n",
    "    labels = tf.keras.layers.Input(shape=(), name=\"labels\")\n",
    "    x = body(inputs)\n",
    "    embeddings = head(x)\n",
    "    x = ArcMarginProduct(nclasses)([embeddings, labels])\n",
    "    outputs = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    model = tf.keras.models.Model(inputs=[inputs, labels], outputs=outputs)\n",
    "    embedding_model = tf.keras.models.Model(inputs=inputs, outputs=embeddings)\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=config['LR'])\n",
    "    metrics = [\n",
    "        positive_distance,\n",
    "        negative_distance,\n",
    "        positive_angular,\n",
    "        negative_angular\n",
    "    ]\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model, embedding_model\n",
    "\n",
    "model, embedding_model = get_model(config[\"IMAGE_SIZE\"], nclasses=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af540fa-073a-42b7-8214-49887f9d3339",
   "metadata": {},
   "source": [
    "## **Evaluate Models Initial Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c090122c-03db-4f81-b771-007b111682d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster_accuracy(X, y):\n",
    "    embeddings = embedding_model.predict(X)\n",
    "    kmeans = KMeans(n_clusters=10, random_state=123)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    \n",
    "    label_mappings = {}\n",
    "    for label in np.unique(labels):\n",
    "        values, counts = np.unique(y[np.where(labels==label)], return_counts=True)\n",
    "        label_mappings[label] = values[np.argmax(counts)]\n",
    "    print(label_mappings)\n",
    "    \n",
    "    map_labels = np.vectorize(lambda x: label_mappings[x])\n",
    "    mapped_labels = map_labels(labels)\n",
    "    return accuracy_score(y.reshape((-1,1)), mapped_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15e79e92-10a5-46ca-9245-c3f7c54c34f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4, 1: 2, 2: 1, 3: 4, 4: 0, 5: 0, 6: 9, 7: 0, 8: 1, 9: 8}\n",
      "0.2509\n"
     ]
    }
   ],
   "source": [
    "acc = kmeans_cluster_accuracy(X_test, y_test)\n",
    "print(acc)\n",
    "run.log({'test/init-test-clustering-accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "621d0e7d-55f2-4bef-bbd1-3b9c3e3adfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3, 1: 2, 2: 0, 3: 1, 4: 4, 5: 4, 6: 0, 7: 0, 8: 1, 9: 9}\n",
      "0.249\n"
     ]
    }
   ],
   "source": [
    "acc = kmeans_cluster_accuracy(X_val, y_val)\n",
    "print(acc)\n",
    "run.log({'test/init-val-clustering-accuracy': acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab4e3c-10b1-45b1-b779-dc7ed5b80e89",
   "metadata": {},
   "source": [
    "## **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86416563-5332-4c1b-8810-aebd6a057b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 [==============================] - 21s 24ms/step - loss: 10.3781 - positive_distance: 0.7698 - negative_distance: 1.0221 - positive_angular: 0.5717 - negative_angular: 0.8320 - val_loss: 15.9444 - val_positive_distance: 0.3848 - val_negative_distance: 0.6704 - val_positive_angular: 0.2355 - val_negative_angular: 0.4495 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 18s 24ms/step - loss: 3.0371 - positive_distance: 0.7328 - negative_distance: 1.2442 - positive_angular: 0.4983 - negative_angular: 0.9244 - val_loss: 6.4186 - val_positive_distance: 0.6411 - val_negative_distance: 1.0955 - val_positive_angular: 0.4201 - val_negative_angular: 0.7959 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 2.1483 - positive_distance: 0.5970 - negative_distance: 1.2854 - positive_angular: 0.3979 - negative_angular: 0.9428 - val_loss: 3.0575 - val_positive_distance: 0.6323 - val_negative_distance: 1.2249 - val_positive_angular: 0.4205 - val_negative_angular: 0.9000 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 1.8190 - positive_distance: 0.5341 - negative_distance: 1.3005 - positive_angular: 0.3528 - negative_angular: 0.9499 - val_loss: 1.9382 - val_positive_distance: 0.4604 - val_negative_distance: 1.3038 - val_positive_angular: 0.3027 - val_negative_angular: 0.9452 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 1.6462 - positive_distance: 0.5069 - negative_distance: 1.3080 - positive_angular: 0.3333 - negative_angular: 0.9535 - val_loss: 1.4864 - val_positive_distance: 0.3978 - val_negative_distance: 1.3251 - val_positive_angular: 0.2595 - val_negative_angular: 0.9576 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.5478 - positive_distance: 0.4747 - negative_distance: 1.3163 - positive_angular: 0.3111 - negative_angular: 0.9571 - val_loss: 2.6031 - val_positive_distance: 0.5778 - val_negative_distance: 1.2360 - val_positive_angular: 0.3810 - val_negative_angular: 0.9051 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.4168 - positive_distance: 0.4547 - negative_distance: 1.3191 - positive_angular: 0.2966 - negative_angular: 0.9588 - val_loss: 1.2769 - val_positive_distance: 0.3417 - val_negative_distance: 1.3431 - val_positive_angular: 0.2258 - val_negative_angular: 0.9651 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.3266 - positive_distance: 0.4367 - negative_distance: 1.3237 - positive_angular: 0.2840 - negative_angular: 0.9609 - val_loss: 2.6382 - val_positive_distance: 0.5692 - val_negative_distance: 1.2407 - val_positive_angular: 0.3676 - val_negative_angular: 0.9072 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 23s 30ms/step - loss: 1.2896 - positive_distance: 0.4287 - negative_distance: 1.3257 - positive_angular: 0.2787 - negative_angular: 0.9618 - val_loss: 1.3027 - val_positive_distance: 0.3425 - val_negative_distance: 1.3452 - val_positive_angular: 0.2254 - val_negative_angular: 0.9662 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.2303 - positive_distance: 0.4139 - negative_distance: 1.3290 - positive_angular: 0.2679 - negative_angular: 0.9634 - val_loss: 1.6226 - val_positive_distance: 0.4141 - val_negative_distance: 1.3183 - val_positive_angular: 0.2731 - val_negative_angular: 0.9517 - lr: 9.0000e-04\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.1723 - positive_distance: 0.4022 - negative_distance: 1.3312 - positive_angular: 0.2605 - negative_angular: 0.9642 - val_loss: 1.8785 - val_positive_distance: 0.4966 - val_negative_distance: 1.2663 - val_positive_angular: 0.3207 - val_negative_angular: 0.9249 - lr: 9.0000e-04\n"
     ]
    }
   ],
   "source": [
    "stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "hist = model.fit(train_ds,\n",
    "                 validation_data=val_ds,\n",
    "                 epochs=config[\"EPOCHS\"],\n",
    "                 callbacks=[stopper, lr_callback, WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd19b3e1-d266-456c-ab48-ea9aba7aeeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step - loss: 1.1031 - positive_distance: 0.3128 - negative_distance: 1.3490 - positive_angular: 0.2045 - negative_angular: 0.9687\n"
     ]
    }
   ],
   "source": [
    "ev = model.evaluate(test_ds, return_dict=True)\n",
    "log_dict = {f'test/{met}': val for met, val in ev.items()}\n",
    "run.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e47b8ff0-447a-491b-8c4d-7126e5ceab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 3, 2: 6, 3: 0, 4: 4, 5: 2, 6: 9, 7: 8, 8: 5, 9: 7}\n",
      "0.9756\n"
     ]
    }
   ],
   "source": [
    "acc = kmeans_cluster_accuracy(X_test, y_test)\n",
    "print(acc)\n",
    "run.log({'test/test-clustering-accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25c16905-c8d8-4ddc-b62a-5298bf1bbadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4, 1: 3, 2: 1, 3: 0, 4: 5, 5: 2, 6: 7, 7: 9, 8: 8, 9: 6}\n",
      "0.9722\n"
     ]
    }
   ],
   "source": [
    "acc = kmeans_cluster_accuracy(X_val, y_val)\n",
    "print(acc)\n",
    "run.log({'test/val-clustering-accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5230d9b-1394-49ea-b440-ff2e0a56a451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10664... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>█████████▁▁</td></tr><tr><td>negative_angular</td><td>▁▆▇▇▇██████</td></tr><tr><td>negative_distance</td><td>▁▆▇▇▇██████</td></tr><tr><td>positive_angular</td><td>█▆▄▃▃▂▂▂▁▁▁</td></tr><tr><td>positive_distance</td><td>█▇▅▄▃▂▂▂▂▁▁</td></tr><tr><td>test/init-test-clustering-accuracy</td><td>▁</td></tr><tr><td>test/init-val-clustering-accuracy</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/negative_angular</td><td>▁</td></tr><tr><td>test/negative_distance</td><td>▁</td></tr><tr><td>test/positive_angular</td><td>▁</td></tr><tr><td>test/positive_distance</td><td>▁</td></tr><tr><td>test/test-clustering-accuracy</td><td>▁</td></tr><tr><td>test/val-clustering-accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▂▁▂▁▁▁</td></tr><tr><td>val_negative_angular</td><td>▁▆▇██▇█▇██▇</td></tr><tr><td>val_negative_distance</td><td>▁▅▇██▇█▇██▇</td></tr><tr><td>val_positive_angular</td><td>▁██▄▂▇▁▆▁▃▄</td></tr><tr><td>val_positive_distance</td><td>▂██▄▂▇▁▆▁▃▅</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>1.27693</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>1.17225</td></tr><tr><td>lr</td><td>0.0009</td></tr><tr><td>negative_angular</td><td>0.96424</td></tr><tr><td>negative_distance</td><td>1.33124</td></tr><tr><td>positive_angular</td><td>0.26055</td></tr><tr><td>positive_distance</td><td>0.40224</td></tr><tr><td>test/init-test-clustering-accuracy</td><td>0.2509</td></tr><tr><td>test/init-val-clustering-accuracy</td><td>0.249</td></tr><tr><td>test/loss</td><td>1.10312</td></tr><tr><td>test/negative_angular</td><td>0.96866</td></tr><tr><td>test/negative_distance</td><td>1.34904</td></tr><tr><td>test/positive_angular</td><td>0.20446</td></tr><tr><td>test/positive_distance</td><td>0.31284</td></tr><tr><td>test/test-clustering-accuracy</td><td>0.9756</td></tr><tr><td>test/val-clustering-accuracy</td><td>0.9722</td></tr><tr><td>val_loss</td><td>1.87849</td></tr><tr><td>val_negative_angular</td><td>0.92487</td></tr><tr><td>val_negative_distance</td><td>1.26627</td></tr><tr><td>val_positive_angular</td><td>0.32068</td></tr><tr><td>val_positive_distance</td><td>0.49659</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">misty-smoke-54</strong>: <a href=\"https://wandb.ai/kmcguigan/deep-clustering-evaluation/runs/279eu9pa\" target=\"_blank\">https://wandb.ai/kmcguigan/deep-clustering-evaluation/runs/279eu9pa</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220308_111554-279eu9pa\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80ab5d-ab77-482a-9d29-89217beee1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
