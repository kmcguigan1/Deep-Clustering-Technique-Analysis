{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e328f5eb-d9d8-4b34-a4f4-c125665a5439",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3d15c6-0708-4a0b-a698-2a37f1e47009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necesary packages\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be88ad98-efd1-4a64-afb4-b356675f9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Basic information\n",
    "    \"AUTHOR\": \"Kiernan\",\n",
    "    \n",
    "    # Data information\n",
    "    \"IMAGE_SIZE\": (28,28,1),\n",
    "    \n",
    "    # Training params\n",
    "    \"LR_STYLE\": \"REDUCE\", #['REDUCE', 'SCHEDULE']\n",
    "    \"LR\": 0.001, #0.000001,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"EPOCHS\": 30,\n",
    "    \n",
    "    # Loss parameters\n",
    "    \"MARGIN\": 0.5,\n",
    "    \n",
    "    \n",
    "    # Model params\n",
    "    # \"RUN_FOR_BASE\": \"3cmjv1lo\",\n",
    "    # \"FREEZE\": \"ALL\", #['ALL', 'BN', 'None'] which layers to freeze in the body model\n",
    "    \n",
    "    # Model params\n",
    "    \"FIRST_FILTERS\": 16,\n",
    "    \"CONV_LAYERS\": 4,\n",
    "    \"N_FILTERS\": 8,\n",
    "    \"KERNEL_SIZE\": (3,3),\n",
    "    \"EMBEDDING_SIZE\": 16,\n",
    "    \"VECTOR_SIZE\": 16,\n",
    "    \"DROPOUT\": 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e537ce47-09e6-48d8-b508-0857f8e70f1e",
   "metadata": {},
   "source": [
    "## **Initialize WANDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ef434e-2881-4669-a98b-a2d849d9e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mall-off-nothing\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\kiern/.netrc\n",
      "C:\\Users\\kiern\\anaconda3\\envs\\deep-clustering-analysis\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kmcguigan/deep-clustering-evaluation/runs/66p409d3\" target=\"_blank\">soft-donkey-66</a></strong> to <a href=\"https://wandb.ai/kmcguigan/deep-clustering-evaluation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from secrets import WANDB\n",
    "wandb.login(key=WANDB)\n",
    "run = wandb.init(project=\"deep-clustering-evaluation\", entity=\"kmcguigan\", group=\"arcface-model\", config=config, job_type=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ed87f-e2fa-453c-bea6-952f21333aec",
   "metadata": {},
   "source": [
    "## **Loading Data**\n",
    "\n",
    "### **Load the presplit data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5eaf12b-fc0a-42ee-831e-ac5d85dde1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (50000, 28, 28, 1) Val data shape: (10000, 28, 28, 1) Test data shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "with open('data/train.npy', mode='rb') as infile:\n",
    "    X_train = np.load(infile, allow_pickle=True)\n",
    "    y_train = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('data/val.npy', mode='rb') as infile:\n",
    "    X_val = np.load(infile, allow_pickle=True)\n",
    "    y_val = np.load(infile, allow_pickle=True)\n",
    "\n",
    "with open('data/test.npy', mode='rb') as infile:\n",
    "    X_test = np.load(infile, allow_pickle=True)\n",
    "    y_test = np.load(infile, allow_pickle=True)\n",
    "\n",
    "print(f\"Train data shape: {X_train.shape} Val data shape: {X_val.shape} Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb1e57-8ae3-4e9f-b000-ceb11cd5a201",
   "metadata": {},
   "source": [
    "### **Create a data generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53203392-5fc1-41f8-a34b-815cff768bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(X, y):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(({\"images\":X,\"labels\":y},y))\n",
    "    ds = ds.cache().shuffle(X.shape[0]+1).batch(config[\"BATCH_SIZE\"]).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = to_dataset(X_train, y_train)\n",
    "val_ds = to_dataset(X_val, y_val)\n",
    "test_ds = to_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27274fe5-369a-4dfe-a06f-4d5dfd19b59f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Define Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c4f932-8181-454a-a4e5-aac29a33c932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_distance(embeddings, squared=False):\n",
    "    dot = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "    square_norm = tf.linalg.diag_part(dot)\n",
    "    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot + tf.expand_dims(square_norm, 0)\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "    if(not squared):\n",
    "        mask = tf.cast(tf.equal(distances, 0.0), tf.float32)\n",
    "        distances = distances + mask * 1e-16\n",
    "        distances = tf.sqrt(distances)\n",
    "        distances = distances * (1.0 - mask)\n",
    "    return distances\n",
    "\n",
    "def angular_distances(embeddings):\n",
    "    embeddings = tf.math.l2_normalize(embeddings, axis=-1)\n",
    "    angular_distances = 1 - tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "    angular_distances = tf.maximum(angular_distances, 0.0)\n",
    "    mask_offdiag = tf.ones_like(angular_distances) - tf.linalg.diag(tf.ones([tf.shape(angular_distances)[0]]))\n",
    "    angular_distances = tf.math.multiply(angular_distances, mask_offdiag)\n",
    "    return angular_distances\n",
    "\n",
    "def apply_metric(embeddings, labels, metric):\n",
    "    adj = tf.equal(labels, tf.transpose(labels))\n",
    "    adj_not = tf.math.logical_not(adj)\n",
    "    adj = tf.cast(adj, tf.float32) - tf.linalg.diag(tf.ones([tf.shape(labels)[0]]))\n",
    "    adj_not = tf.cast(adj_not, tf.float32)\n",
    "    distances = metric(embeddings)\n",
    "    pos_dist = tf.math.multiply(distances, adj)\n",
    "    neg_dist = tf.math.multiply(distances, adj_not)\n",
    "    pos_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(pos_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    neg_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(neg_dist, mask=tf.math.equal(adj_not, 1.0)))\n",
    "    return pos_dist_mean, neg_dist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327feae2-b259-4285-8d9f-37bd93a3b311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positive_distance(labels, embeddings):\n",
    "    labels = tf.expand_dims(labels,-1)\n",
    "    adj = tf.equal(labels, tf.transpose(labels))\n",
    "    adj = tf.cast(adj, tf.float32) - tf.linalg.diag(tf.ones([tf.shape(labels)[0]]))\n",
    "    distances = pairwise_distance(embeddings)\n",
    "    pos_dist = tf.math.multiply(distances, adj)\n",
    "    pos_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(pos_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return pos_dist_mean\n",
    "\n",
    "def negative_distance(labels, embeddings):\n",
    "    labels = tf.expand_dims(labels,-1)\n",
    "    adj_not = tf.math.logical_not(tf.equal(labels, tf.transpose(labels)))\n",
    "    adj_not_float = tf.cast(adj_not, tf.float32)\n",
    "    distances = pairwise_distance(embeddings)\n",
    "    neg_dist = tf.math.multiply(distances, adj_not_float)\n",
    "    neg_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(neg_dist, mask=adj_not))\n",
    "    return neg_dist_mean\n",
    "\n",
    "def positive_angular(labels, embeddings):\n",
    "    labels = tf.expand_dims(labels,-1)\n",
    "    adj = tf.equal(labels, tf.transpose(labels))\n",
    "    adj = tf.cast(adj, tf.float32) - tf.linalg.diag(tf.ones([tf.shape(labels)[0]]))\n",
    "    distances = angular_distances(embeddings)\n",
    "    pos_dist = tf.math.multiply(distances, adj)\n",
    "    pos_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(pos_dist, mask=tf.math.equal(adj, 1.0)))\n",
    "    return pos_dist_mean\n",
    "\n",
    "def negative_angular(labels, embeddings):\n",
    "    labels = tf.expand_dims(labels,-1)\n",
    "    adj = tf.math.logical_not(tf.equal(labels, tf.transpose(labels)))\n",
    "    adj_float = tf.cast(adj, tf.float32)\n",
    "    distances = angular_distances(embeddings)\n",
    "    neg_dist = tf.math.multiply(distances, adj_float)\n",
    "    neg_dist_mean = tf.reduce_mean(tf.ragged.boolean_mask(neg_dist, mask=adj))\n",
    "    return neg_dist_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6963757-8a58-42ce-ae38-1d3d32232830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(plot=False, batch_size=config['BATCH_SIZE'], epochs=config['EPOCHS']):\n",
    "    lr_start   = config['LR']\n",
    "    lr_max     = config['LR'] * 5 * batch_size  \n",
    "    lr_min     = config['LR']\n",
    "    lr_ramp_ep = 4\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.9\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "    if(plot):\n",
    "        epochs = list(range(epochs))\n",
    "        learning_rates = [lrfn(x) for x in epochs]\n",
    "        plt.scatter(epochs,learning_rates)\n",
    "        ax = plt.gca()\n",
    "        ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "        plt.show()\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback\n",
    "\n",
    "if(config[\"LR_STYLE\"] == \"SCHEDULE\"):\n",
    "    lr_callback = get_lr_callback(plot=True)\n",
    "elif(config[\"LR_STYLE\"] == \"REDUCE\"):\n",
    "    lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=2)\n",
    "else:\n",
    "    raise Exception(f\"config LR_STYLE {config['LR_STYLE']} is not understood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc8af1-6703-4636-bcb6-bdeb2ed58e4d",
   "metadata": {},
   "source": [
    "## **Create Model**\n",
    "\n",
    "### **Load the pretrained body model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8612f35-945d-42d9-a587-2cedbb64a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "def freeze_BN(model):\n",
    "    # Unfreeze layers while leaving BatchNorm layers frozen\n",
    "    for layer in model.layers:\n",
    "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "            \n",
    "def freeze_none(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc18a926-7262-4eb0-8896-b3cf7fdf5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"body\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 14, 14, 16)       64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 14, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 16)        144       \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 16)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,408\n",
      "Trainable params: 3,312\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_body(image_shape):\n",
    "    inputs = tf.keras.layers.Input(shape=image_shape)\n",
    "    \n",
    "    def conv_block(layer_inputs, n_filters, kernel_size, **kwargs):\n",
    "        x = tf.keras.layers.Conv2D(n_filters, kernel_size, padding=\"same\", **kwargs)(layer_inputs)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        return x\n",
    "    \n",
    "    x = conv_block(inputs, config[\"FIRST_FILTERS\"], config[\"KERNEL_SIZE\"], strides=2)\n",
    "    # x = tf.keras.layers.BatchNormalization()(x)\n",
    "    for _ in range(config[\"CONV_LAYERS\"]):\n",
    "        x = conv_block(x, config[\"N_FILTERS\"], config[\"KERNEL_SIZE\"])\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(config[\"EMBEDDING_SIZE\"], (1,1), padding=\"same\")(x)\n",
    "    outputs = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    return tf.keras.models.Model(inputs=inputs, outputs=outputs, name=\"body\")\n",
    "\n",
    "body = create_body(X_train.shape[1:])\n",
    "body.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0346c-5250-4554-a204-86b7f9d8aa95",
   "metadata": {},
   "source": [
    "### **Create the head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3540639c-6bd9-4fca-af1e-db7983acdb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 16)]              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 16)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272\n",
      "Trainable params: 272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class ArcMarginLogits(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements the arc margin loss.\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False, ls_eps=0.0, **kwargs):\n",
    "        super(ArcMarginLogits, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            'scale': self.scale,\n",
    "            'margin': self.margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        # get the cosine between the vecors and all the classes\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0),\n",
    "            name=\"cosine_similarity\"\n",
    "        )\n",
    "        # extract the positive mask\n",
    "        positive_mask = tf.one_hot(y, depth=self.n_classes, dtype=tf.int8, name=\"positive_mask\")\n",
    "        positive_bool_mask = tf.cast(positive_mask, dtype=tf.bool, name=\"positive_boolean_mask\")\n",
    "        # extract theta\n",
    "        theta = tf.acos(K.clip(cosine, -1.0+K.epsilon(), 1.0-K.epsilon()), name=\"theta_extraction\")\n",
    "        theta_mask = tf.cast(tf.where(theta + self.margin > math.pi, 1, 0), dtype=tf.bool, name=\"theta_mask\")\n",
    "        margin_theta = tf.where(positive_bool_mask, theta + self.margin, theta, name=\"margin_added_theta\")\n",
    "        margin_adjuested_theta = tf.where(tf.logical_and(positive_bool_mask,theta_mask), math.pi, margin_theta, name=\"margin_adjusted_theta\")\n",
    "        # convert the angular differences back to cosine similarities\n",
    "        cosine = tf.cos(margin_adjuested_theta, name=\"margin_added_cosine\")\n",
    "        return tf.math.multiply(cosine, self.scale, name=\"scaled_margin_added_cosine\")\n",
    "    \n",
    "    \n",
    "def create_head(input_shape):\n",
    "    inputs = tf.keras.layers.Input(shape=(input_shape,))\n",
    "    x = tf.keras.layers.Dropout(config[\"DROPOUT\"])(inputs)\n",
    "    x = tf.keras.layers.Dense(config['VECTOR_SIZE'])(x)\n",
    "    outputs = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1))(x)\n",
    "    return tf.keras.models.Model(inputs=inputs, outputs=outputs, name=\"head\")\n",
    "\n",
    "head = create_head(input_shape=config['EMBEDDING_SIZE'])\n",
    "head.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67956e-783d-4796-a5f7-3170418a83b7",
   "metadata": {},
   "source": [
    "### **Create the loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f44477-5a3e-4a1a-a5ed-06eedc2a953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arcmarginproduct class keras layer\n",
    "import math\n",
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False, ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dbc381-be0e-4de1-90fc-22910301960a",
   "metadata": {},
   "source": [
    "### **Create the full model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe1b374-3ff4-483b-9e14-5396b2734c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " images (InputLayer)            [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " body (Functional)              (None, 16)           3408        ['images[0][0]']                 \n",
      "                                                                                                  \n",
      " head (Functional)              (None, 16)           272         ['body[0][0]']                   \n",
      "                                                                                                  \n",
      " labels (InputLayer)            [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " arc_margin_product (ArcMarginP  (None, 10)          160         ['head[0][0]',                   \n",
      " roduct)                                                          'labels[0][0]']                 \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 10)           0           ['arc_margin_product[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,840\n",
      "Trainable params: 3,744\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(image_size, nclasses):\n",
    "    inputs = tf.keras.layers.Input(shape=image_size, name=\"images\")\n",
    "    labels = tf.keras.layers.Input(shape=(), name=\"labels\")\n",
    "    x = body(inputs)\n",
    "    embeddings = head(x)\n",
    "    x = ArcMarginProduct(nclasses)([embeddings, labels])\n",
    "    outputs = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    model = tf.keras.models.Model(inputs=[inputs, labels], outputs=outputs)\n",
    "    embedding_model = tf.keras.models.Model(inputs=inputs, outputs=embeddings)\n",
    "    \n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(), tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)]\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=config['LR'])\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model, embedding_model\n",
    "\n",
    "model, embedding_model = get_model(config[\"IMAGE_SIZE\"], nclasses=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af540fa-073a-42b7-8214-49887f9d3339",
   "metadata": {},
   "source": [
    "## **Evaluate Models Initial Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c090122c-03db-4f81-b771-007b111682d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster_accuracy(X, y):\n",
    "    embeddings = embedding_model.predict(X)\n",
    "    kmeans = KMeans(n_clusters=10, random_state=123)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    \n",
    "    label_mappings = {}\n",
    "    for label in np.unique(labels):\n",
    "        values, counts = np.unique(y[np.where(labels==label)], return_counts=True)\n",
    "        label_mappings[label] = values[np.argmax(counts)]\n",
    "    print(label_mappings)\n",
    "    \n",
    "    map_labels = np.vectorize(lambda x: label_mappings[x])\n",
    "    mapped_labels = map_labels(labels)\n",
    "    return accuracy_score(y.reshape((-1,1)), mapped_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15e79e92-10a5-46ca-9245-c3f7c54c34f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 8, 2: 1, 3: 9, 4: 8, 5: 5, 6: 9, 7: 0, 8: 0, 9: 1}\n",
      "0.2324\n"
     ]
    }
   ],
   "source": [
    "acc = kmeans_cluster_accuracy(X_test, y_test)\n",
    "print(acc)\n",
    "run.log({'test/init-test-clustering-accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "621d0e7d-55f2-4bef-bbd1-3b9c3e3adfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 8, 1: 1, 2: 3, 3: 0, 4: 5, 5: 4, 6: 3, 7: 1, 8: 4, 9: 0}\n",
      "0.2412\n"
     ]
    }
   ],
   "source": [
    "acc = kmeans_cluster_accuracy(X_val, y_val)\n",
    "print(acc)\n",
    "run.log({'test/init-val-clustering-accuracy': acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab4e3c-10b1-45b1-b779-dc7ed5b80e89",
   "metadata": {},
   "source": [
    "## **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86416563-5332-4c1b-8810-aebd6a057b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 [==============================] - 19s 23ms/step - loss: 6.2654 - sparse_categorical_accuracy: 0.4525 - sparse_top_k_categorical_accuracy: 0.6354 - val_loss: 4.4248 - val_sparse_categorical_accuracy: 0.4636 - val_sparse_top_k_categorical_accuracy: 0.8208 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 1.7259 - sparse_categorical_accuracy: 0.7993 - sparse_top_k_categorical_accuracy: 0.9426 - val_loss: 1.6050 - val_sparse_categorical_accuracy: 0.8061 - val_sparse_top_k_categorical_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 1.3985 - sparse_categorical_accuracy: 0.8352 - sparse_top_k_categorical_accuracy: 0.9560 - val_loss: 3.4877 - val_sparse_categorical_accuracy: 0.5908 - val_sparse_top_k_categorical_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 1.2389 - sparse_categorical_accuracy: 0.8565 - sparse_top_k_categorical_accuracy: 0.9623 - val_loss: 1.9476 - val_sparse_categorical_accuracy: 0.7822 - val_sparse_top_k_categorical_accuracy: 0.9388 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 1.1058 - sparse_categorical_accuracy: 0.8674 - sparse_top_k_categorical_accuracy: 0.9673 - val_loss: 1.5006 - val_sparse_categorical_accuracy: 0.8232 - val_sparse_top_k_categorical_accuracy: 0.9562 - lr: 9.0000e-04\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 1.0315 - sparse_categorical_accuracy: 0.8758 - sparse_top_k_categorical_accuracy: 0.9697 - val_loss: 1.0243 - val_sparse_categorical_accuracy: 0.8749 - val_sparse_top_k_categorical_accuracy: 0.9714 - lr: 9.0000e-04\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.9821 - sparse_categorical_accuracy: 0.8799 - sparse_top_k_categorical_accuracy: 0.9715 - val_loss: 2.1569 - val_sparse_categorical_accuracy: 0.7359 - val_sparse_top_k_categorical_accuracy: 0.9438 - lr: 9.0000e-04\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 18s 24ms/step - loss: 0.9396 - sparse_categorical_accuracy: 0.8845 - sparse_top_k_categorical_accuracy: 0.9724 - val_loss: 1.1825 - val_sparse_categorical_accuracy: 0.8626 - val_sparse_top_k_categorical_accuracy: 0.9660 - lr: 9.0000e-04\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.8858 - sparse_categorical_accuracy: 0.8906 - sparse_top_k_categorical_accuracy: 0.9740 - val_loss: 1.0202 - val_sparse_categorical_accuracy: 0.8788 - val_sparse_top_k_categorical_accuracy: 0.9672 - lr: 8.1000e-04\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.8410 - sparse_categorical_accuracy: 0.8957 - sparse_top_k_categorical_accuracy: 0.9760 - val_loss: 1.0445 - val_sparse_categorical_accuracy: 0.8773 - val_sparse_top_k_categorical_accuracy: 0.9674 - lr: 8.1000e-04\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.8119 - sparse_categorical_accuracy: 0.8968 - sparse_top_k_categorical_accuracy: 0.9777 - val_loss: 1.0876 - val_sparse_categorical_accuracy: 0.8676 - val_sparse_top_k_categorical_accuracy: 0.9664 - lr: 8.1000e-04\n",
      "Epoch 12/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.7532 - sparse_categorical_accuracy: 0.9042 - sparse_top_k_categorical_accuracy: 0.9790 - val_loss: 1.5217 - val_sparse_categorical_accuracy: 0.7952 - val_sparse_top_k_categorical_accuracy: 0.9631 - lr: 7.2900e-04\n",
      "Epoch 13/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.7582 - sparse_categorical_accuracy: 0.9033 - sparse_top_k_categorical_accuracy: 0.9783 - val_loss: 1.0033 - val_sparse_categorical_accuracy: 0.8770 - val_sparse_top_k_categorical_accuracy: 0.9713 - lr: 7.2900e-04\n",
      "Epoch 14/30\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.7193 - sparse_categorical_accuracy: 0.9080 - sparse_top_k_categorical_accuracy: 0.9797 - val_loss: 1.0230 - val_sparse_categorical_accuracy: 0.8732 - val_sparse_top_k_categorical_accuracy: 0.9696 - lr: 7.2900e-04\n",
      "Epoch 15/30\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.7137 - sparse_categorical_accuracy: 0.9079 - sparse_top_k_categorical_accuracy: 0.9803 - val_loss: 1.3582 - val_sparse_categorical_accuracy: 0.8354 - val_sparse_top_k_categorical_accuracy: 0.9657 - lr: 7.2900e-04\n",
      "Epoch 16/30\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.9119 - sparse_top_k_categorical_accuracy: 0.9804 - val_loss: 1.6118 - val_sparse_categorical_accuracy: 0.7761 - val_sparse_top_k_categorical_accuracy: 0.9572 - lr: 6.5610e-04\n",
      "Epoch 17/30\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.6681 - sparse_categorical_accuracy: 0.9127 - sparse_top_k_categorical_accuracy: 0.9819 - val_loss: 1.7639 - val_sparse_categorical_accuracy: 0.7773 - val_sparse_top_k_categorical_accuracy: 0.9444 - lr: 6.5610e-04\n"
     ]
    }
   ],
   "source": [
    "stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "hist = model.fit(train_ds,\n",
    "                 validation_data=val_ds,\n",
    "                 epochs=config[\"EPOCHS\"],\n",
    "                 callbacks=[stopper, lr_callback, WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd19b3e1-d266-456c-ab48-ea9aba7aeeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step - loss: 0.8931 - sparse_categorical_accuracy: 0.8838 - sparse_top_k_categorical_accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "ev = model.evaluate(test_ds, return_dict=True)\n",
    "log_dict = {f'test/{met}': val for met, val in ev.items()}\n",
    "run.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e47b8ff0-447a-491b-8c4d-7126e5ceab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 8, 2: 0, 3: 3, 4: 4, 5: 7, 6: 2, 7: 5, 8: 6, 9: 9}\n",
      "0.9801\n"
     ]
    }
   ],
   "source": [
    "acc = kmeans_cluster_accuracy(X_test, y_test)\n",
    "print(acc)\n",
    "run.log({'test/test-clustering-accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25c16905-c8d8-4ddc-b62a-5298bf1bbadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2, 1: 7, 2: 5, 3: 8, 4: 1, 5: 6, 6: 9, 7: 3, 8: 0, 9: 4}\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "acc = kmeans_cluster_accuracy(X_val, y_val)\n",
    "print(acc)\n",
    "run.log({'test/val-clustering-accuracy': acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df60ab4f-7a5b-45b2-a014-5e5bfaced6f6",
   "metadata": {},
   "source": [
    "## **Evalueate Separation on Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cdde67a-c9fd-405f-9f94-3fe5fc882d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_distance 0.45751404762268066 negative_distance 1.4312160015106201 positive_angular 0.12867270410060883 negative_angular 1.0515965223312378\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedding_model.predict(X_test)\n",
    "pd = positive_distance(y_test, embeddings)\n",
    "nd = negative_distance(y_test, embeddings)\n",
    "pa = positive_angular(y_test, embeddings)\n",
    "na = negative_angular(y_test, embeddings)\n",
    "print(f\"positive_distance {pd} negative_distance {nd} positive_angular {pa} negative_angular {na}\")\n",
    "run.log({'test/positive_distance': pd})\n",
    "run.log({'test/negative_distance': nd})\n",
    "run.log({'test/positive_angular': pa})\n",
    "run.log({'test/negative_angular': na})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5230d9b-1394-49ea-b440-ff2e0a56a451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26200... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>████▆▆▆▆▄▄▄▂▂▂▂▁▁</td></tr><tr><td>sparse_categorical_accuracy</td><td>▁▆▇▇▇▇███████████</td></tr><tr><td>sparse_top_k_categorical_accuracy</td><td>▁▇▇██████████████</td></tr><tr><td>test/init-test-clustering-accuracy</td><td>▁</td></tr><tr><td>test/init-val-clustering-accuracy</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/negative_angular</td><td>▁</td></tr><tr><td>test/negative_distance</td><td>▁</td></tr><tr><td>test/positive_angular</td><td>▁</td></tr><tr><td>test/positive_distance</td><td>▁</td></tr><tr><td>test/sparse_categorical_accuracy</td><td>▁</td></tr><tr><td>test/sparse_top_k_categorical_accuracy</td><td>▁</td></tr><tr><td>test/test-clustering-accuracy</td><td>▁</td></tr><tr><td>test/val-clustering-accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>█▂▆▃▂▁▃▁▁▁▁▂▁▁▂▂▃</td></tr><tr><td>val_sparse_categorical_accuracy</td><td>▁▇▃▆▇█▆████▇██▇▆▆</td></tr><tr><td>val_sparse_top_k_categorical_accuracy</td><td>▁▇▅▆▇█▇████████▇▇</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>12</td></tr><tr><td>best_val_loss</td><td>1.00333</td></tr><tr><td>epoch</td><td>16</td></tr><tr><td>loss</td><td>0.66815</td></tr><tr><td>lr</td><td>0.00066</td></tr><tr><td>sparse_categorical_accuracy</td><td>0.91272</td></tr><tr><td>sparse_top_k_categorical_accuracy</td><td>0.9819</td></tr><tr><td>test/init-test-clustering-accuracy</td><td>0.2324</td></tr><tr><td>test/init-val-clustering-accuracy</td><td>0.2412</td></tr><tr><td>test/loss</td><td>0.89309</td></tr><tr><td>test/negative_angular</td><td>1.0516</td></tr><tr><td>test/negative_distance</td><td>1.43122</td></tr><tr><td>test/positive_angular</td><td>0.12867</td></tr><tr><td>test/positive_distance</td><td>0.45751</td></tr><tr><td>test/sparse_categorical_accuracy</td><td>0.8838</td></tr><tr><td>test/sparse_top_k_categorical_accuracy</td><td>0.9756</td></tr><tr><td>test/test-clustering-accuracy</td><td>0.9801</td></tr><tr><td>test/val-clustering-accuracy</td><td>0.98</td></tr><tr><td>val_loss</td><td>1.76386</td></tr><tr><td>val_sparse_categorical_accuracy</td><td>0.7773</td></tr><tr><td>val_sparse_top_k_categorical_accuracy</td><td>0.9444</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">soft-donkey-66</strong>: <a href=\"https://wandb.ai/kmcguigan/deep-clustering-evaluation/runs/66p409d3\" target=\"_blank\">https://wandb.ai/kmcguigan/deep-clustering-evaluation/runs/66p409d3</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220324_213215-66p409d3\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80ab5d-ab77-482a-9d29-89217beee1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
